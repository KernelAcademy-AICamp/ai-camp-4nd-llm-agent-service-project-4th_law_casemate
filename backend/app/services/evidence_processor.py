"""
ì¦ê±° íŒŒì¼ ì²˜ë¦¬ ì„œë¹„ìŠ¤
- ìµœì†Œ ë¹„ìš©, ìµœëŒ€ íš¨ìœ¨ì„ ìœ„í•œ í•˜ì´ë¸Œë¦¬ë“œ ì²˜ë¦¬ ì „ëµ
- AUDIO: STT (OpenAI Whisper)
- PDF: í…ìŠ¤íŠ¸ ì¶”ì¶œ (ë¬´ë£Œ) â†’ ì‹¤íŒ¨ ì‹œ Vision API
- IMAGE: Vision API (Low/High Detail)
"""

from fastapi import UploadFile
from openai import AsyncOpenAI
import os
import logging
from typing import Literal, Dict, Any
from io import BytesIO

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

FileType = Literal["IMAGE", "PDF", "AUDIO", "UNKNOWN"]
DetailLevel = Literal["low", "high"]


class EvidenceProcessor:
    """ì¦ê±° íŒŒì¼ ì²˜ë¦¬ í”„ë¡œì„¸ì„œ"""

    def __init__(self):
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        self.client = AsyncOpenAI(api_key=api_key)

    def identify_file_type(self, file: UploadFile) -> FileType:
        """
        íŒŒì¼ íƒ€ì… ì‹ë³„

        Args:
            file: ì—…ë¡œë“œëœ íŒŒì¼

        Returns:
            FileType: IMAGE, PDF, AUDIO, UNKNOWN
        """
        content_type = file.content_type or ""
        filename = file.filename or ""

        # MIME íƒ€ì… ê¸°ë°˜ ì‹ë³„
        if content_type.startswith("audio/"):
            return "AUDIO"
        elif content_type.startswith("image/"):
            return "IMAGE"
        elif content_type == "application/pdf" or filename.lower().endswith(".pdf"):
            return "PDF"

        # í™•ì¥ì ê¸°ë°˜ ì‹ë³„ (fallback)
        ext = filename.lower().split(".")[-1] if "." in filename else ""
        if ext in ["mp3", "wav", "m4a", "ogg", "webm", "flac", "mpeg", "mpga"]:
            return "AUDIO"
        elif ext in ["jpg", "jpeg", "png", "gif", "bmp", "webp", "tiff"]:
            return "IMAGE"
        elif ext == "pdf":
            return "PDF"

        logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” íŒŒì¼ íƒ€ì…: {content_type}, {filename}")
        return "UNKNOWN"

    async def process_audio(self, file: UploadFile) -> Dict[str, Any]:
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ (STT)

        Args:
            file: ì˜¤ë””ì˜¤ íŒŒì¼

        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        from app.services.stt_service import STTService

        try:
            logger.info(f"ğŸ¤ ì˜¤ë””ì˜¤ íŒŒì¼ STT ì‹œì‘: {file.filename}")

            stt_service = STTService()
            text = await stt_service.run(file)

            logger.info(f"âœ… STT ì™„ë£Œ: {len(text)}ì ì¶”ì¶œ")
            logger.debug(f"ğŸ“ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ (ì²˜ìŒ 200ì): {text[:200]}")

            return {
                "success": True,
                "type": "AUDIO",
                "method": "openai-whisper",
                "text": text,
                "char_count": len(text),
                "cost_estimate": "ì €ë¹„ìš© (STT)"
            }

        except Exception as e:
            logger.error(f"âŒ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            return {
                "success": False,
                "type": "AUDIO",
                "error": str(e)
            }

    async def process_pdf(self, file: UploadFile, detail: DetailLevel = "high") -> Dict[str, Any]:
        """
        PDF íŒŒì¼ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ì¶”ì¶œ â†’ Vision API)

        Args:
            file: PDF íŒŒì¼
            detail: Vision API detail ë ˆë²¨ (low/high)

        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            import fitz  # PyMuPDF

            logger.info(f"ğŸ“„ PDF íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {file.filename}")

            # íŒŒì¼ ë‚´ìš© ì½ê¸°
            await file.seek(0)
            file_content = await file.read()

            # PDF ì—´ê¸°
            pdf_document = fitz.open(stream=file_content, filetype="pdf")
            total_pages = len(pdf_document)
            logger.info(f"ğŸ“š PDF ì´ í˜ì´ì§€ ìˆ˜: {total_pages}")

            extracted_text = ""
            image_pages = []

            # ê° í˜ì´ì§€ë³„ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„
            for page_num in range(total_pages):
                page = pdf_document[page_num]
                page_text = page.get_text()

                # í˜ì´ì§€ë‹¹ 20ì ë¯¸ë§Œì´ë©´ ì´ë¯¸ì§€í˜• í˜ì´ì§€ë¡œ ê°„ì£¼
                if len(page_text.strip()) < 20:
                    logger.warning(f"âš ï¸ í˜ì´ì§€ {page_num + 1}: í…ìŠ¤íŠ¸ ë¶€ì¡± ({len(page_text.strip())}ì) - ì´ë¯¸ì§€í˜• í˜ì´ì§€")
                    image_pages.append(page_num)
                else:
                    extracted_text += f"\n\n=== í˜ì´ì§€ {page_num + 1} ===\n{page_text}"

            pdf_document.close()

            # í…ìŠ¤íŠ¸ PDF (ëª¨ë“  í˜ì´ì§€ì—ì„œ ì¶©ë¶„í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œë¨)
            if len(image_pages) == 0:
                logger.info(f"âœ… í…ìŠ¤íŠ¸ PDF: {len(extracted_text)}ì ì¶”ì¶œ (ë¹„ìš© 0ì›)")
                logger.debug(f"ğŸ“ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ (ì²˜ìŒ 200ì): {extracted_text[:200]}")

                return {
                    "success": True,
                    "type": "PDF",
                    "method": "pymupdf-text",
                    "text": extracted_text.strip(),
                    "char_count": len(extracted_text),
                    "total_pages": total_pages,
                    "cost_estimate": "ë¬´ë£Œ (í…ìŠ¤íŠ¸ ì¶”ì¶œ)"
                }

            # ì´ë¯¸ì§€í˜• PDF (ì¼ë¶€ í˜ì´ì§€ê°€ ì´ë¯¸ì§€)
            logger.warning(f"âš ï¸ ì´ë¯¸ì§€í˜• PDF: {len(image_pages)}ê°œ í˜ì´ì§€ë¥¼ Vision APIë¡œ ì²˜ë¦¬ í•„ìš”")

            # Vision APIë¡œ ì´ë¯¸ì§€ í˜ì´ì§€ ì²˜ë¦¬
            vision_text = await self._process_pdf_with_vision(
                file_content, image_pages, detail
            )

            combined_text = extracted_text + "\n\n" + vision_text

            logger.info(f"âœ… í•˜ì´ë¸Œë¦¬ë“œ PDF ì²˜ë¦¬ ì™„ë£Œ: {len(combined_text)}ì")
            logger.debug(f"ğŸ“ ìµœì¢… í…ìŠ¤íŠ¸ (ì²˜ìŒ 200ì): {combined_text[:200]}")

            return {
                "success": True,
                "type": "PDF",
                "method": "pymupdf+vision",
                "text": combined_text.strip(),
                "char_count": len(combined_text),
                "total_pages": total_pages,
                "text_pages": total_pages - len(image_pages),
                "image_pages": len(image_pages),
                "cost_estimate": f"ì €ë¹„ìš© (Vision API {len(image_pages)}í˜ì´ì§€)"
            }

        except ImportError:
            logger.error("âŒ PyMuPDF(fitz)ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install pymupdf")
            return {
                "success": False,
                "type": "PDF",
                "error": "PyMuPDF not installed"
            }
        except Exception as e:
            logger.error(f"âŒ PDF ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            return {
                "success": False,
                "type": "PDF",
                "error": str(e)
            }

    async def _process_pdf_with_vision(
        self,
        pdf_content: bytes,
        page_numbers: list[int],
        detail: DetailLevel
    ) -> str:
        """
        PDFì˜ ì´ë¯¸ì§€í˜• í˜ì´ì§€ë¥¼ Vision APIë¡œ ì²˜ë¦¬

        Args:
            pdf_content: PDF íŒŒì¼ ë‚´ìš©
            page_numbers: ì²˜ë¦¬í•  í˜ì´ì§€ ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸
            detail: low/high

        Returns:
            ì¶”ì¶œëœ í…ìŠ¤íŠ¸
        """
        import fitz
        import base64

        pdf_document = fitz.open(stream=pdf_content, filetype="pdf")
        extracted_text = ""

        for page_num in page_numbers:
            page = pdf_document[page_num]

            # í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
            pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))  # 2ë°° í•´ìƒë„
            img_bytes = pix.tobytes("png")

            # Base64 ì¸ì½”ë”©
            img_base64 = base64.b64encode(img_bytes).decode("utf-8")

            # Vision API í˜¸ì¶œ
            try:
                response = await self.client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {
                            "role": "user",
                            "content": [
                                {
                                    "type": "text",
                                    "text": "ì´ ì´ë¯¸ì§€ì—ì„œ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì •í™•í•˜ê²Œ ì¶”ì¶œí•´ì£¼ì„¸ìš”. ë²•ë¥  ë¬¸ì„œì´ë¯€ë¡œ ë²ˆí˜¸, ê¸°í˜¸, ì„œëª… ë“±ë„ ì •í™•íˆ ì¸ì‹í•´ì£¼ì„¸ìš”."
                                },
                                {
                                    "type": "image_url",
                                    "image_url": {
                                        "url": f"data:image/png;base64,{img_base64}",
                                        "detail": detail
                                    }
                                }
                            ]
                        }
                    ],
                    max_tokens=2000
                )

                page_text = response.choices[0].message.content
                extracted_text += f"\n\n=== í˜ì´ì§€ {page_num + 1} (Vision API) ===\n{page_text}"

                logger.info(f"âœ… Vision API - í˜ì´ì§€ {page_num + 1}: {len(page_text)}ì ì¶”ì¶œ")

            except Exception as e:
                logger.error(f"âŒ Vision API ì‹¤íŒ¨ - í˜ì´ì§€ {page_num + 1}: {str(e)}")

        pdf_document.close()
        return extracted_text

    async def process_image(
        self,
        file: UploadFile,
        detail: DetailLevel = "high"
    ) -> Dict[str, Any]:
        """
        ì´ë¯¸ì§€ íŒŒì¼ ì²˜ë¦¬ (ë¡œì»¬ OCR â†’ Vision API)

        Args:
            file: ì´ë¯¸ì§€ íŒŒì¼
            detail: low (85í† í°) / high (512px íƒ€ì¼ ë¶„ì„)

        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            logger.info(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {file.filename} (detail={detail})")

            # íŒŒì¼ ë‚´ìš© ì½ê¸°
            await file.seek(0)
            file_content = await file.read()

            # 1ë‹¨ê³„: ë¡œì»¬ OCR ì‹œë„ (EasyOCR)
            try:
                import easyocr
                from io import BytesIO
                from PIL import Image

                logger.info("ğŸ” ë¡œì»¬ OCR ì‹œë„ (EasyOCR)")

                # EasyOCR Reader ì´ˆê¸°í™” (í•œê¸€, ì˜ì–´)
                reader = easyocr.Reader(['ko', 'en'], gpu=False, verbose=False)

                # ì´ë¯¸ì§€ ë°”ì´íŠ¸ë¥¼ numpy arrayë¡œ ë³€í™˜
                img = Image.open(BytesIO(file_content))
                import numpy as np
                img_array = np.array(img)

                # OCR ì‹¤í–‰
                result = reader.readtext(img_array)

                if result and len(result) > 0:
                    # ê²°ê³¼ë¥¼ ìœ„ì¹˜ë³„ë¡œ ì •ë ¬ (ìœ„â†’ì•„ë˜, ì™¼ìª½â†’ì˜¤ë¥¸ìª½)
                    sorted_result = sorted(result, key=lambda x: (x[0][0][1], x[0][0][0]))
                    text = '\n'.join([item[1] for item in sorted_result])

                    # ìµœì†Œ 20ì ì´ìƒ ì¶”ì¶œë˜ë©´ ì„±ê³µìœ¼ë¡œ ê°„ì£¼
                    if len(text.strip()) >= 20:
                        logger.info(f"âœ… ë¡œì»¬ OCR ì„±ê³µ: {len(text)}ì ì¶”ì¶œ (ë¹„ìš© 0ì›)")
                        logger.debug(f"ğŸ“ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ (ì²˜ìŒ 200ì): {text[:200]}")

                        return {
                            "success": True,
                            "type": "IMAGE",
                            "method": "easyocr-local",
                            "text": text,
                            "char_count": len(text),
                            "cost_estimate": "ë¬´ë£Œ (ë¡œì»¬ OCR)"
                        }
                    else:
                        logger.warning(f"âš ï¸ ë¡œì»¬ OCR í…ìŠ¤íŠ¸ ë¶€ì¡±: {len(text)}ì â†’ Vision APIë¡œ ì „í™˜")

                else:
                    logger.warning("âš ï¸ ë¡œì»¬ OCR ê²°ê³¼ ì—†ìŒ â†’ Vision APIë¡œ ì „í™˜")

            except ImportError:
                logger.warning("âš ï¸ EasyOCR ë¯¸ì„¤ì¹˜ â†’ Vision APIë¡œ ì „í™˜")
            except Exception as ocr_error:
                logger.warning(f"âš ï¸ ë¡œì»¬ OCR ì‹¤íŒ¨: {str(ocr_error)} â†’ Vision APIë¡œ ì „í™˜")

            # 2ë‹¨ê³„: Vision API í˜¸ì¶œ (í”„ë¡¬í”„íŠ¸ ê°œì„ )
            import base64

            logger.info("ğŸŒ OpenAI Vision API í˜¸ì¶œ")

            # Base64 ì¸ì½”ë”©
            img_base64 = base64.b64encode(file_content).decode("utf-8")

            # Vision API í˜¸ì¶œ (ë²•ë¥  ë§¥ë½ ê°•ì¡°)
            response = await self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": """ë‹¹ì‹ ì€ ë²•ì› ì œì¶œìš© ì¦ê±° ìë£Œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì´ ì´ë¯¸ì§€ëŠ” ë²•ì  ì†Œì†¡ ì¦ê±°ë¡œ ì‚¬ìš©ë  ë¬¸ì„œì…ë‹ˆë‹¤.
ì´ë¯¸ì§€ ë‚´ ëª¨ë“  í…ìŠ¤íŠ¸, ëŒ€í™” ë‚´ìš©, ì‹œê°„, ë°œì‹ ì ì •ë³´ë¥¼ ë¹ ì§ì—†ì´ ì •í™•í•˜ê²Œ ì¶”ì¶œí•˜ì„¸ìš”.

í˜•ì‹:
- ë¬¸ì„œ/ëŒ€í™”ì˜ ê²½ìš°: [ë°œì‹ ì/ì‘ì„±ì] [ì‹œê°„] ë‚´ìš©
- ì¼ë°˜ ë¬¸ì„œì˜ ê²½ìš°: í…ìŠ¤íŠ¸ë¥¼ ì›ë³¸ êµ¬ì¡° ê·¸ëŒ€ë¡œ ì¶”ì¶œ"""
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/png;base64,{img_base64}",
                                    "detail": detail
                                }
                            }
                        ]
                    }
                ],
                max_tokens=2000
            )

            text = response.choices[0].message.content or ""

            # OpenAIê°€ ê±°ì ˆí–ˆëŠ”ì§€ í™•ì¸
            if "ì£„ì†¡í•˜ì§€ë§Œ" in text or "ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in text or len(text.strip()) < 20:
                logger.warning(f"âš ï¸ OpenAI Vision ê±°ì ˆ ë˜ëŠ” ê²°ê³¼ ë¶€ì¡±: {text[:100]}")
                return {
                    "success": False,
                    "type": "IMAGE",
                    "method": "openai-vision-rejected",
                    "text": text,
                    "char_count": len(text),
                    "error": "Vision APIê°€ í…ìŠ¤íŠ¸ ì¶”ì¶œì„ ê±°ì ˆí–ˆìŠµë‹ˆë‹¤. ë¡œì»¬ OCRì„ ì‚¬ìš©í•˜ê±°ë‚˜ ë‹¤ë¥¸ ì´ë¯¸ì§€ë¥¼ ì‹œë„í•˜ì„¸ìš”."
                }

            logger.info(f"âœ… Vision API OCR ì™„ë£Œ: {len(text)}ì ì¶”ì¶œ (detail={detail})")
            logger.debug(f"ğŸ“ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ (ì²˜ìŒ 200ì): {text[:200]}")

            return {
                "success": True,
                "type": "IMAGE",
                "method": f"openai-vision-{detail}",
                "text": text,
                "char_count": len(text),
                "cost_estimate": "ì €ë¹„ìš© (Vision API)" if detail == "low" else "ì¤‘ë¹„ìš© (Vision API High)"
            }

        except Exception as e:
            logger.error(f"âŒ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            return {
                "success": False,
                "type": "IMAGE",
                "error": str(e)
            }

    async def process(
        self,
        file: UploadFile,
        detail: DetailLevel = "high"
    ) -> Dict[str, Any]:
        """
        ì¦ê±° íŒŒì¼ ì²˜ë¦¬ ë©”ì¸ ë©”ì„œë“œ

        Args:
            file: ì—…ë¡œë“œëœ íŒŒì¼
            detail: Vision API detail ë ˆë²¨ (ì´ë¯¸ì§€/ì´ë¯¸ì§€í˜• PDFìš©)

        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        logger.info(f"ğŸš€ ì¦ê±° íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {file.filename}")

        # 1. íŒŒì¼ íƒ€ì… ì‹ë³„
        file_type = self.identify_file_type(file)
        logger.info(f"ğŸ“‹ íŒŒì¼ íƒ€ì…: {file_type}")

        # 2. íƒ€ì…ë³„ ì²˜ë¦¬
        if file_type == "AUDIO":
            return await self.process_audio(file)

        elif file_type == "PDF":
            return await self.process_pdf(file, detail)

        elif file_type == "IMAGE":
            return await self.process_image(file, detail)

        else:
            logger.error(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ íƒ€ì…: {file_type}")
            return {
                "success": False,
                "type": "UNKNOWN",
                "error": f"Unsupported file type: {file_type}"
            }
