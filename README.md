# CaseMate - LLM í”„ë¡œì íŠ¸

FastAPI ë°±ì—”ë“œì™€ React + TypeScript í”„ë¡ íŠ¸ì—”ë“œë¥¼ ì‚¬ìš©í•˜ëŠ” LLM ê¸°ë°˜ ëŒ€í™” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
CaseMate/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py              # FastAPI ì•± ì§„ì…ì 
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ routes.py        # API ë¼ìš°íŠ¸
â”‚   â”‚   â”œâ”€â”€ models/              # ë°ì´í„° ëª¨ë¸
â”‚   â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ services/            # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ llm_service.py   # LLM ì„œë¹„ìŠ¤
â”‚   â”œâ”€â”€ requirements.txt         # Python ì˜ì¡´ì„±
â”‚   â””â”€â”€ .env.example            # í™˜ê²½ ë³€ìˆ˜ ì˜ˆì œ
â”œâ”€â”€ frontend/                    # React + TypeScript + Vite
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.tsx             # ë©”ì¸ ì»´í¬ë„ŒíŠ¸
â”‚   â”‚   â”œâ”€â”€ App.css             # ìŠ¤íƒ€ì¼ì‹œíŠ¸
â”‚   â”‚   â”œâ”€â”€ types.ts            # TypeScript íƒ€ì… ì •ì˜
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ api.ts          # API ì„œë¹„ìŠ¤
â”‚   â”‚   â””â”€â”€ main.tsx            # ì§„ì…ì 
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â””â”€â”€ vite.config.ts          # Vite ì„¤ì •
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸš€ ì‹œì‘í•˜ê¸°

### 1. ë°±ì—”ë“œ ì„¤ì •

```bash
# ê°€ìƒí™˜ê²½ ìƒì„±
cd backend
python -m venv venv

# ê°€ìƒí™˜ê²½ í™œì„±í™”
# macOS/Linux:
source venv/bin/activate
# Windows:
# venv\Scripts\activate

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
cp .env.example .env
# .env íŒŒì¼ì„ ì—´ì–´ API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”

# ì„œë²„ ì‹¤í–‰
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### 2. í”„ë¡ íŠ¸ì—”ë“œ ì‹¤í–‰

```bash
# í”„ë¡ íŠ¸ì—”ë“œ ë””ë ‰í† ë¦¬ë¡œ ì´ë™
cd frontend

# ì˜ì¡´ì„± ì„¤ì¹˜ (ì²˜ìŒ í•œ ë²ˆë§Œ)
npm install

# ê°œë°œ ì„œë²„ ì‹¤í–‰
npm run dev
```

ë¸Œë¼ìš°ì €ì—ì„œ `http://localhost:3000` ì ‘ì†

### 3. í•œ ë²ˆì— ì‹¤í–‰ (ì„ íƒì‚¬í•­)

```bash
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ
./run.sh
```

## ğŸ”§ API ì—”ë“œí¬ì¸íŠ¸

- `GET /` - API ë£¨íŠ¸
- `GET /health` - í—¬ìŠ¤ ì²´í¬
- `POST /api/chat` - LLMê³¼ ëŒ€í™”
- `GET /api/conversations/{conversation_id}` - ëŒ€í™” ê¸°ë¡ ì¡°íšŒ
- `DELETE /api/conversations/{conversation_id}` - ëŒ€í™” ê¸°ë¡ ì‚­ì œ

## ğŸ“ LLM í†µí•©

í˜„ì¬ ì½”ë“œëŠ” ì„ì‹œ ì—ì½” ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤. ì‹¤ì œ LLMì„ ì‚¬ìš©í•˜ë ¤ë©´:

1. `backend/app/services/llm_service.py` íŒŒì¼ ìˆ˜ì •
2. í•„ìš”í•œ LLM ë¼ì´ë¸ŒëŸ¬ë¦¬ ì£¼ì„ í•´ì œ (`requirements.txt`)
3. API í‚¤ë¥¼ `.env` íŒŒì¼ì— ì„¤ì •
4. LLM í˜¸ì¶œ ì½”ë“œ êµ¬í˜„

### OpenAI ì˜ˆì œ

```python
from openai import AsyncOpenAI

client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

response = await client.chat.completions.create(
    model="gpt-4",
    messages=self.conversations[conversation_id]
)
```

## ğŸ› ï¸ ê°œë°œ

- ë°±ì—”ë“œëŠ” `http://localhost:8000`ì—ì„œ ì‹¤í–‰
- í”„ë¡ íŠ¸ì—”ë“œëŠ” `http://localhost:3000`ì—ì„œ ì‹¤í–‰ (Vite ê°œë°œ ì„œë²„)
- FastAPI ë¬¸ì„œëŠ” `http://localhost:8000/docs`ì—ì„œ í™•ì¸ ê°€ëŠ¥

### í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œ

```bash
cd frontend

# ê°œë°œ ì„œë²„ ì‹œì‘ (í•« ë¦¬ë¡œë“œ ì§€ì›)
npm run dev

# í”„ë¡œë•ì…˜ ë¹Œë“œ
npm run build

# ë¦°íŠ¸ ê²€ì‚¬
npm run lint

# ë¹Œë“œëœ ì•± ë¯¸ë¦¬ë³´ê¸°
npm run preview
```

ViteëŠ” ë‹¤ìŒ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤:
- âš¡ï¸ ì´ˆê³ ì† HMR (Hot Module Replacement)
- ğŸ“¦ ìµœì í™”ëœ í”„ë¡œë•ì…˜ ë¹Œë“œ
- ğŸ”§ TypeScript ì§€ì›
- ğŸ¨ CSS ëª¨ë“ˆ ë° ì „ì²˜ë¦¬ê¸° ì§€ì›

## ğŸ“¦ ì˜ì¡´ì„±

### Backend
- FastAPI - ì›¹ í”„ë ˆì„ì›Œí¬
- Uvicorn - ASGI ì„œë²„
- Pydantic - ë°ì´í„° ê²€ì¦

### Frontend
- React 19 - UI ë¼ì´ë¸ŒëŸ¬ë¦¬
- TypeScript - íƒ€ì… ì•ˆì „ì„±
- Vite - ë¹Œë“œ ë„êµ¬ ë° ê°œë°œ ì„œë²„
- Modern CSS3

## ğŸ” ë³´ì•ˆ

- í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” CORS ì„¤ì •ì„ ì œí•œí•˜ì„¸ìš”
- API í‚¤ë¥¼ `.env` íŒŒì¼ì— ì €ì¥í•˜ê³  ì ˆëŒ€ ì»¤ë°‹í•˜ì§€ ë§ˆì„¸ìš”
- HTTPSë¥¼ ì‚¬ìš©í•˜ì„¸ìš”

## ğŸ“„ ë¼ì´ì„ ìŠ¤

MIT License
