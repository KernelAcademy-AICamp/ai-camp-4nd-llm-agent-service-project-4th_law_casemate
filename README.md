# CaseMate - LLM í”„ë¡œì íŠ¸

FastAPI ë°±ì—”ë“œì™€ JavaScript í”„ë¡ íŠ¸ì—”ë“œë¥¼ ì‚¬ìš©í•˜ëŠ” LLM ê¸°ë°˜ ëŒ€í™” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
CaseMate/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py              # FastAPI ì•± ì§„ì…ì 
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ routes.py        # API ë¼ìš°íŠ¸
â”‚   â”‚   â”œâ”€â”€ models/              # ë°ì´í„° ëª¨ë¸
â”‚   â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ services/            # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ llm_service.py   # LLM ì„œë¹„ìŠ¤
â”‚   â”œâ”€â”€ requirements.txt         # Python ì˜ì¡´ì„±
â”‚   â””â”€â”€ .env.example            # í™˜ê²½ ë³€ìˆ˜ ì˜ˆì œ
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html              # ë©”ì¸ HTML
â”‚   â””â”€â”€ static/
â”‚       â”œâ”€â”€ css/
â”‚       â”‚   â””â”€â”€ style.css       # ìŠ¤íƒ€ì¼ì‹œíŠ¸
â”‚       â””â”€â”€ js/
â”‚           â””â”€â”€ app.js          # JavaScript ë¡œì§
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸš€ ì‹œì‘í•˜ê¸°

### 1. ë°±ì—”ë“œ ì„¤ì •

```bash
# ê°€ìƒí™˜ê²½ ìƒì„±
cd backend
python -m venv venv

# ê°€ìƒí™˜ê²½ í™œì„±í™”
# macOS/Linux:
source venv/bin/activate
# Windows:
# venv\Scripts\activate

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
cp .env.example .env
# .env íŒŒì¼ì„ ì—´ì–´ API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”

# ì„œë²„ ì‹¤í–‰
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### 2. í”„ë¡ íŠ¸ì—”ë“œ ì‹¤í–‰

```bash
# ê°„ë‹¨í•œ HTTP ì„œë²„ ì‹¤í–‰ (Python)
cd frontend
python -m http.server 3000

# ë˜ëŠ” Node.js http-server ì‚¬ìš©
npx http-server -p 3000
```

ë¸Œë¼ìš°ì €ì—ì„œ `http://localhost:3000` ì ‘ì†

## ğŸ”§ API ì—”ë“œí¬ì¸íŠ¸

- `GET /` - API ë£¨íŠ¸
- `GET /health` - í—¬ìŠ¤ ì²´í¬
- `POST /api/chat` - LLMê³¼ ëŒ€í™”
- `GET /api/conversations/{conversation_id}` - ëŒ€í™” ê¸°ë¡ ì¡°íšŒ
- `DELETE /api/conversations/{conversation_id}` - ëŒ€í™” ê¸°ë¡ ì‚­ì œ

## ğŸ“ LLM í†µí•©

í˜„ì¬ ì½”ë“œëŠ” ì„ì‹œ ì—ì½” ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤. ì‹¤ì œ LLMì„ ì‚¬ìš©í•˜ë ¤ë©´:

1. `backend/app/services/llm_service.py` íŒŒì¼ ìˆ˜ì •
2. í•„ìš”í•œ LLM ë¼ì´ë¸ŒëŸ¬ë¦¬ ì£¼ì„ í•´ì œ (`requirements.txt`)
3. API í‚¤ë¥¼ `.env` íŒŒì¼ì— ì„¤ì •
4. LLM í˜¸ì¶œ ì½”ë“œ êµ¬í˜„

### OpenAI ì˜ˆì œ

```python
from openai import AsyncOpenAI

client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

response = await client.chat.completions.create(
    model="gpt-4",
    messages=self.conversations[conversation_id]
)
```

## ğŸ› ï¸ ê°œë°œ

- ë°±ì—”ë“œëŠ” `http://localhost:8000`ì—ì„œ ì‹¤í–‰
- í”„ë¡ íŠ¸ì—”ë“œëŠ” `http://localhost:3000`ì—ì„œ ì‹¤í–‰
- FastAPI ë¬¸ì„œëŠ” `http://localhost:8000/docs`ì—ì„œ í™•ì¸ ê°€ëŠ¥

## ğŸ“¦ ì˜ì¡´ì„±

### Backend
- FastAPI - ì›¹ í”„ë ˆì„ì›Œí¬
- Uvicorn - ASGI ì„œë²„
- Pydantic - ë°ì´í„° ê²€ì¦

### Frontend
- ìˆœìˆ˜ JavaScript (í”„ë ˆì„ì›Œí¬ ì—†ìŒ)
- HTML5/CSS3

## ğŸ” ë³´ì•ˆ

- í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” CORS ì„¤ì •ì„ ì œí•œí•˜ì„¸ìš”
- API í‚¤ë¥¼ `.env` íŒŒì¼ì— ì €ì¥í•˜ê³  ì ˆëŒ€ ì»¤ë°‹í•˜ì§€ ë§ˆì„¸ìš”
- HTTPSë¥¼ ì‚¬ìš©í•˜ì„¸ìš”

## ğŸ“„ ë¼ì´ì„ ìŠ¤

MIT License
